{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[297 156 240 240]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture('videos/face.mp4')\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    face_casc = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    face_rects = face_casc.detectMultiScale(frame)\n",
    "    if len(face_rects)>0:\n",
    "        print(face_rects)\n",
    "        break\n",
    "# print(face_rects)\n",
    "\n",
    "# converting list into tuple\n",
    "face_x, face_y, w, h = tuple(face_rects[0])\n",
    "track_window = (face_x, face_y, w, h)\n",
    "\n",
    "# ROI for tracking\n",
    "roi = frame[face_y:face_y+h,\n",
    "           face_x:face_x+w]\n",
    "\n",
    "# hsv color mapping\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram to target on each frame for cam shift calculation\n",
    "# Calculates a histogram of a set of arrays.\n",
    "\"\"\"Parameters:\n",
    "images – Source arrays. They all should have the same depth, CV_8U or\n",
    "CV_32F , and the same size. Each of them can have an arbitrary number\n",
    "of channels.\n",
    "nimages – Number of source images.\n",
    "channels – List of the dims channels used to compute the histogram. \n",
    "The first array channels are numerated from 0 to images[0].channels()-1\n",
    ", second array channels are counted from images[0].channels() to images\n",
    "[0].channels() + images[1].channels()-1, and so on.\n",
    "mask – Optional mask. If the matrix is not empty, it must be 8-bit \n",
    "array of the same size as images[i] . The non-zero mask elements mark\n",
    "the array elements counted in the histogram.\n",
    "hist – Output histogram, which is a dense or sparse dims -dimensional\n",
    "array.\n",
    "dims – Histogram dimensionality that must be positive and not greater\n",
    "than CV_MAX_DIMS (equal to 32 in the current OpenCV version).\n",
    "histSize – Array of histogram sizes in each dimension.\n",
    "ranges – Array of the dims arrays of the histogram bin boundaries in\n",
    "each dimension. \n",
    "\"\"\"\n",
    "\n",
    "roi_hist = cv2.calcHist([hsv_roi],\n",
    "                       [0],\n",
    "                       None,\n",
    "                       [180],\n",
    "                       [0,180])\n",
    "\n",
    "# normalizing the histogram\n",
    "cv2.normalize(roi_hist,\n",
    "             roi_hist,\n",
    "             0,\n",
    "             255,\n",
    "             cv2.NORM_MINMAX)\n",
    "\"\"\"Parameters:\t\n",
    "src – input array.\n",
    "dst – output array of the same size as src .\n",
    "alpha – norm value to normalize to or the lower range boundary in case\n",
    "of the range normalization.\n",
    "beta – upper range boundary in case of the range normalization; it is \n",
    "not used for the norm normalization.\n",
    "normType – normalization type (see the details below).\n",
    "dtype – when negative, the output array has the same type as src; \n",
    "otherwise, it has the same number of channels as src and \n",
    "depth =CV_MAT_DEPTH(dtype).\n",
    "mask – optional operation mask.\"\"\"\n",
    "\n",
    "# setting termination criteria\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Back Projection\n",
    "        \"\"\"Back Projection is way of recording how well pixels of given\n",
    "        image fit distribution of pixels in a histogram model. To make\n",
    "        it simpler: For Back Projection, you calculate histogram model\n",
    "        of feature and then use it to find this feature in an image.\n",
    "        Application example: If you have histogram of flesh color (say,\n",
    "        Hue-Saturation histogram ), then you can use it to find flesh \n",
    "        color areas in an image:\n",
    "        \n",
    "        Parameters: images – Source arrays. They all should have same \n",
    "        depth, CV_8U or CV_32F , and the same size. \n",
    "        nimages – Number of source images.\n",
    "        channels – The list of channels used to compute back projection\n",
    "        . The number of channels must match histogram dimensionality. \n",
    "        hist – Input histogram that can be dense or sparse.\n",
    "        backProject – Destination back projection array that is \n",
    "        single-channel array of the same size and depth as images[0] .\n",
    "        ranges – Array of arrays of the histogram bin boundaries in \n",
    "        each dimension. See calcHist() .\n",
    "        scale – Optional scale factor for the output back projection.\n",
    "        \"\"\"        \n",
    "        dest = cv2.calcBackProject([hsv],\n",
    "                                      [0],\n",
    "                                      roi_hist,\n",
    "                                      [0,180],\n",
    "                                      1)\n",
    "        \n",
    "        # Cam shift to get new coordinated of rectangle\n",
    "        \"\"\"Camshift or Continuously Adaptive Meanshift is enhanced \n",
    "        version of the meanshift algorithm which provides more accuracy\n",
    "        and robustness to the model. With help of Camshift algorithm, \n",
    "        size of window keeps updating when tracking window tries to \n",
    "        converge. The tracking is done by using the color information\n",
    "        of the object. Also, it provides the best fitting tracking \n",
    "        window for object tracking. It applies meanshift first and \n",
    "        then updates the size of the window as:\n",
    "           s =  2 * sqrt{M_{00}/{256}] \n",
    "        It then calculates the best fitting ellipse to it and again \n",
    "        applies the meanshift with the newly scaled search window and\n",
    "        the previous window. This process is continued until required\n",
    "        accuracy is met.\n",
    "        Note: For more information about meanshift refer to Python \n",
    "        OpenCV: Meanshift\n",
    "        \"\"\"\n",
    "        ret, track_window = cv2.CamShift(dest,\n",
    "                                         track_window,\n",
    "                                         term_crit)\n",
    "        # drawing new rectangle\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        \"\"\"Finds four vertices of rotated rect. Useful to draw \n",
    "        rotated rectangle.\"\"\"\n",
    "        \n",
    "        pts = np.int0(pts)\n",
    "        \"\"\"int0 is alias for intp; this, in turn, is Integer used for\n",
    "        indexing (same as C ssize_t; normally either int32 or int64\"\"\"\n",
    "        \n",
    "        img2 = cv2.polylines(frame,\n",
    "                            [pts],\n",
    "                            True,\n",
    "                            (0,255,0),\n",
    "                            5)\n",
    "        \"\"\"method is used to draw a polygon on any image.\n",
    "        Parameters:\n",
    "        image: It is the image on which circle is to be drawn.\n",
    "        pts: Array of polygonal curves.\n",
    "        npts: Array of polygon vertex counters.\n",
    "        ncontours: Number of curves.\n",
    "        isClosed: Flag indicating whether the drawn polylines are \n",
    "        closed or not. If they are closed, the function draws a line\n",
    "        from the last vertex of each curve to its first vertex.\n",
    "        color: It is the color of polyline to be drawn. For BGR, we\n",
    "        pass a tuple.\n",
    "        thickness: It is thickness of the polyline edges.\"\"\"\n",
    "        \n",
    "        cv2.imshow(\"Cam Shift\", img2)\n",
    "        \n",
    "        if cv2.waitKey(30) & 0xFF==27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
