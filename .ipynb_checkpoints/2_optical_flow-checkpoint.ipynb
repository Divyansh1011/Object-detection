{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "\"\"\"Interest points : Points in the image which are invariant to \n",
    "rotation, translation, intensity and scale changes. (Basically, robust\n",
    "and reliable). There are different interest points such as corners, \n",
    "edges, blobs etc.\n",
    "Feature Descriptors : These describe the image patch around interest \n",
    "points in vectors. They can be as simple as raw pixel values or \n",
    "complicated like Histogram of Gradients (HoG) etc.\n",
    "\"\"\"\n",
    "# Corner\n",
    "\"Intersection of 2 edges identified by sudden change in image brightness\"\n",
    "\n",
    "# Harris Corner Detector\n",
    "\"\"\"The Harris Corner Detector algorithm in simple words is as follows:\n",
    "STEP 1. It determines which windows (small image patches) produce very\n",
    "large variations in intensity when moved in both X and Y directions \n",
    "(i.e. gradients).\n",
    "STEP 2. With each such window found, a score R is computed.\n",
    "STEP 3. After applying a threshold to this score, important corners \n",
    "are selected & marked.\"\"\"\n",
    "\n",
    "\n",
    "# Shi-tomasi corner detection\n",
    "\"\"\"Corners can be detected by looking for significant change in all \n",
    "direction. Considering a small window on image then scanning whole\n",
    "image can help in looking for corners. If this small window consists of\n",
    "a corner then shifting this small window in any direction whould \n",
    "result in a large change in appearance.\n",
    "\"\"\"\n",
    "\n",
    "# Initializing frame and capturing video\n",
    "# To turn web cam on, replace video path by 0\n",
    "cap = cv2.VideoCapture('videos/man.mp4')\n",
    "\n",
    "# Reading capture and first frame\n",
    "ret, first_frame = cap.read()\n",
    "# cap. read() returns a bool ( True / False ). If the frame is read \n",
    "# correctly, it will be True .\n",
    "\n",
    "\n",
    "# Finding strongest corners\n",
    "\"\"\"cv2.goodFeaturesToTrack(gray_img, maxc, Q, minD)\n",
    "Parameters :\n",
    "image – Grayscale image with integral values.\n",
    "maxCorners – Maximum number of corners to return. If there are more\n",
    "corners than are found, the strongest of them is returned.\n",
    "qualityLevel – Parameter characterizing the minimal accepted quality \n",
    "of image corners. \n",
    "minDistance – Minimum possible Euclidean distance between the returned\n",
    "corners.\n",
    "mask – Optional region of interest. If the image is not empty (it needs\n",
    "to have the type CV_8UC1 and the same size as image ), it specifies \n",
    "region in which the corners are detected.\n",
    "blockSize – Size of an average block for computing a derivative \n",
    "covariation matrix over each pixel neighborhood.\n",
    "\"\"\"\n",
    "\n",
    "# Converting frame to grayscale\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Shi-tomasi corner detection parameters\n",
    "st_params = dict(maxCorners=30,\n",
    "                qualityLevel=0.2,\n",
    "                minDistance=10,\n",
    "                blockSize=7)\n",
    "\n",
    "prev = cv2.goodFeaturesToTrack(prev_gray,\n",
    "                              mask=None,\n",
    "                              **st_params)\n",
    "\n",
    "\n",
    "# Optical flow\n",
    "\"\"\"Pattern of apparent motion of image objects between two consecutive\n",
    "frames caused by movement of object or camera. It is 2D vector field \n",
    "where each vector is a displacement vector showing the movement of \n",
    "points from first frame to second. \n",
    "It works on 2 assumptions:\n",
    "1) Pixel densities of an object do not change between consecutive \n",
    "frames.\n",
    "2) Neighbouring pixels have similar motion.\"\"\"\n",
    "\n",
    "# Lucas-Kanade method - to track points found by shi-tomasi corner\n",
    "# detection algorithm\n",
    "\"\"\"Differential method for optical flow developed. It assumes that \n",
    "flow is essentially constant in a local neighbourhood of pixel under \n",
    "consideration, and solves basic optical flow equations for all pixels \n",
    "in that neighbourhood, by least squares criterion.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Color for optical flow\n",
    "color = (255, 2, 0)\n",
    "\n",
    "# Creating an image with same dimensions as frame for later drawing \n",
    "# purposes\n",
    "mask = np.zeros_like(first_frame)\n",
    "#  Return array of given shape and type as given array, with zeros\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    try:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    except:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "    # Calculating optical flow by Lucas-Kanade\n",
    "    \"\"\"Calculates optical flow for sparse feature set using iterative\n",
    "    Lucas-Kanade method with pyramids.\n",
    "    Parameters:\n",
    "    prevImg, nextImg, prevPTS,\n",
    "    nxtPts:nextPts: output vector of 2D points (with single-precision \n",
    "    floating-point coordinates) containing the calculated new positions\n",
    "    of input features in the second image.\n",
    "    winSize: size of the search window at each pyramid level.\n",
    "    maxLevel: 0-based maximal pyramid level number; if set to 0, \n",
    "    pyramids are not used (single level), if set to 1, two levels are\n",
    "    used, and so on; if pyramids are passed to input then algorithm \n",
    "    will use as many levels as pyramids have but no more than maxLevel.\n",
    "    \n",
    "    criteria: parameter, specifying termination criteria of iterative\n",
    "    search algorithm.\n",
    "    \n",
    "    Return: \n",
    "    nextPts – output vector of 2D points (with single-precision \n",
    "    floating-point coordinates) containing calculated new positions of\n",
    "    input features in the second image.\n",
    "    status – output status vector (of unsigned chars); each element of\n",
    "    vector is set to 1 if flow for corresponding features has been \n",
    "    found, otherwise, it is set to 0.\n",
    "    err – output vector of errors; each element of the vector is set to\n",
    "    an error for the corresponding feature, type of the error measure \n",
    "    can be set in flags parameter; if the flow wasn’t found then error\n",
    "    is not defined\n",
    "    \"\"\"\n",
    "    # Lucas-Kanade optical flow parameters\n",
    "    lk_params = dict(winSize=(15,15), \n",
    "            maxLevel=2, \n",
    "      criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 1))\n",
    "\n",
    "    next, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev, None, **lk_params )\n",
    "    \n",
    "    # select good feature for previous position\n",
    "    good_prev = prev[status==1]\n",
    "    \n",
    "    # select good feature for next position\n",
    "    good_next = next[status==1]\n",
    "    \n",
    "    # drawing optical flow track\n",
    "    for i, (new, old) in enumerate(zip(good_next, good_prev)):\n",
    "        \n",
    "        # numpy.ravel()\n",
    "        \"\"\"returns contiguous flattened array(1D array with all input-\n",
    "        array elements and with same type as it). A copy is made only\n",
    "        if needed.\"\"\"\n",
    "        # Return coordinates for new point\n",
    "        a, b = new.ravel()\n",
    "        \n",
    "        # Return coordinates for old point\n",
    "        c, d = old.ravel()\n",
    "        \n",
    "        # Draw line between new and old position\n",
    "        mask = cv2.line(mask, (a,b), (c,d), color, 2)\n",
    "        \n",
    "        # Draw filled circle\n",
    "        frame = cv2.circle(frame, \n",
    "                          (a,b),\n",
    "                          2,\n",
    "                          color, \n",
    "                          -1)\n",
    "        \n",
    "    # Overlay optical flow on original frame\n",
    "    \"add two images with the OpenCV function, cv.add()\"\n",
    "    output = cv2.add(frame, mask)\n",
    "    \n",
    "    # Update previous frame\n",
    "    prev_gray = gray.copy()\n",
    "    \n",
    "    \n",
    "    # Update previous good features\n",
    "    prev = good_next.reshape(-1, 1, 2)\n",
    "    \n",
    "    \n",
    "    # Open new window and display the output\n",
    "    cv2.imshow(\"Optical Flow\", np.hstack([mask,output]))\n",
    "    \n",
    "    # CLose the frame\n",
    "    # Press esc to exit\n",
    "    if cv2.waitKey(50) & 0xFF==27:\n",
    "        break\n",
    "        \n",
    "# Release and Destroy\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
