{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "# print(type(frame), type(ret))\n",
    "\n",
    "# CascadeClassifier\n",
    "\"\"\"Detects objects of different sizes in input image, detected objects \n",
    "are returned as list of rectangles.\"\"\"\n",
    "\n",
    "# inital face cascade\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    face_casc = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # detectMultiscale\n",
    "    \"\"\"Detects objects of different sizes in the input image. The detected\n",
    "    objects are returned as a list of rectangles.\n",
    "    \"\"\"\n",
    "    face_rects = face_casc.detectMultiScale(frame)\n",
    "    if len(face_rects)>0:\n",
    "        break\n",
    "\n",
    "# converting list into tuple\n",
    "face_x, face_y, w, h = tuple(face_rects[0])\n",
    "track_window = (face_x, face_y, w, h)\n",
    "\n",
    "# ROI for tracking\n",
    "roi = frame[face_y:face_y+h,\n",
    "           face_x:face_x+w]\n",
    "\n",
    "# hsv color mapping\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram to target on each frame for mean shift calculation\n",
    "# Calculates a histogram of a set of arrays.\n",
    "\"\"\"Parameters:\n",
    "images – Source arrays. They all should have the same depth, CV_8U or\n",
    "CV_32F , and the same size. Each of them can have an arbitrary number\n",
    "of channels.\n",
    "nimages – Number of source images.\n",
    "channels – List of the dims channels used to compute the histogram. \n",
    "The first array channels are numerated from 0 to images[0].channels()-1\n",
    ", second array channels are counted from images[0].channels() to images\n",
    "[0].channels() + images[1].channels()-1, and so on.\n",
    "mask – Optional mask. If the matrix is not empty, it must be 8-bit \n",
    "array of the same size as images[i] . The non-zero mask elements mark\n",
    "the array elements counted in the histogram.\n",
    "hist – Output histogram, which is a dense or sparse dims -dimensional\n",
    "array.\n",
    "dims – Histogram dimensionality that must be positive and not greater\n",
    "than CV_MAX_DIMS (equal to 32 in the current OpenCV version).\n",
    "histSize – Array of histogram sizes in each dimension.\n",
    "ranges – Array of the dims arrays of the histogram bin boundaries in\n",
    "each dimension. \n",
    "\"\"\"\n",
    "roi_hist = cv2.calcHist(images = [hsv_roi],\n",
    "                       channels = [0],\n",
    "                       mask = None,\n",
    "                       histSize = [180],\n",
    "                       ranges = [0,180])\n",
    "\n",
    "# normalizing the histogram\n",
    "cv2.normalize(roi_hist,\n",
    "             roi_hist,\n",
    "             0,\n",
    "             255,\n",
    "             cv2.NORM_MINMAX)\n",
    "\n",
    "# setting termination criteria\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Back Projection\n",
    "        \"\"\"Back Projection is way of recording how well pixels of given\n",
    "        image fit distribution of pixels in a histogram model. To make\n",
    "        it simpler: For Back Projection, you calculate histogram model\n",
    "        of feature and then use it to find this feature in an image.\n",
    "        Application example: If you have histogram of flesh color (say,\n",
    "        Hue-Saturation histogram ), then you can use it to find flesh \n",
    "        color areas in an image:\n",
    "        \n",
    "        Parameters: images – Source arrays. They all should have same \n",
    "        depth, CV_8U or CV_32F , and the same size. \n",
    "        nimages – Number of source images.\n",
    "        channels – The list of channels used to compute back projection\n",
    "        . The number of channels must match histogram dimensionality. \n",
    "        hist – Input histogram that can be dense or sparse.\n",
    "        backProject – Destination back projection array that is \n",
    "        single-channel array of the same size and depth as images[0] .\n",
    "        ranges – Array of arrays of the histogram bin boundaries in \n",
    "        each dimension. See calcHist() .\n",
    "        scale – Optional scale factor for the output back projection.\n",
    "        \"\"\"\n",
    "        dest_roi = cv2.calcBackProject(images = [hsv],\n",
    "                                      channels = [0],\n",
    "                                      hist = roi_hist,\n",
    "                                      ranges = [0,180],\n",
    "                                      scale = 1)\n",
    "        \n",
    "        # Mean shift Algo\n",
    "        \"\"\"The idea behind meanshift is that in meanshift algorithm \n",
    "        every instance of video is checked in form of pixel \n",
    "        distribution in that frame. We define an initial window, \n",
    "        generally a square or a circle for which the positions are \n",
    "        specified by ourself which identifies the area of maximum pixel\n",
    "        distribution and tries to keep track of that area in the video\n",
    "        so that when the video is running our tracking window also \n",
    "        moves towards the region of maximum pixel distribution. The \n",
    "        direction of movement depends upon difference between center\n",
    "        of our tracking window and the centroid of all the k-pixels \n",
    "        inside that window.\n",
    "        Meanshift is a very useful method to keep track of a particular\n",
    "        object inside video. Meanshift can separate static background \n",
    "        of a video and the moving foreground object.\"\"\"        \n",
    "        \n",
    "        ret, track_window = cv2.meanShift(dest_roi,\n",
    "                                         track_window,\n",
    "                                         term_crit)\n",
    "        # drawing new rectangle\n",
    "        x,y,w,h = track_window\n",
    "        \n",
    "        # display in new window\n",
    "        img2 = cv2.rectangle(frame, (x,y),\n",
    "                            (x+w, y+h),\n",
    "                            (255,255,0),\n",
    "                             3)\n",
    "        cv2.imshow(\"Face Tracker\", img2)\n",
    "        \n",
    "        if cv2.waitKey(30) & 0xFF==27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
